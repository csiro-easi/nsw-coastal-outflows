{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d8de42f-ca26-45cc-a236-08c309b258ab",
   "metadata": {},
   "source": [
    "# <u>NSW DCCEEW training â€“ Demo 4: TSS flux using catchment rainfall</u>\n",
    "\n",
    " - <b>Author</b>: Eric.Lehmann@csiro.au\n",
    " - <b>Release date / version</b>: Aug. 2024, v1.0\n",
    " - <b>Dev. platform</b>: CSIRO ADIAS/ADS (hub.adias.aquawatchaus.space)\n",
    " - <b>Server profile</b>: EASI Open Data Cube No ML &ndash; Version 2023.10.2 \n",
    " - <b>Server resources</b>: 32 CPU &ndash; 64GB RAM\n",
    " - <b>Python kernel</b>: `Python 3 (ipykernel)`\n",
    " - <b>Dask</b>: Local cluster\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84ceb3c-027c-4c8c-b9ac-1902fd308fb5",
   "metadata": {},
   "source": [
    "<b>Contents</b>\n",
    "  - [Overview](#Overview)\n",
    "  - [User parameters](#User-parameters)\n",
    "  - [Notebook setup](#Notebook-setup)\n",
    "  - [Dask](#Dask)\n",
    "  - [Data loading, pre-processing, TSS calculation](#Data-loading,-pre-processing,-TSS-calculation)\n",
    "  - [TSS flux using BoM rainfall](#TSS-flux-using-BoM-rainfall)\n",
    "    - [Create mask of pixels in front of river mouth](#Create-mask-of-pixels-in-front-of-river-mouth)\n",
    "    - [Spatial TSS statistics at river mouth](#Spatial-TSS-statistics-at-river-mouth)\n",
    "    - [Load catchment shape file](#Load-catchment-shape-file)\n",
    "    - [BOM rainfall](#BOM-rainfall)\n",
    "    - [Catchment 'cookie-cutting'](#Catchment-'cookie-cutting')\n",
    "    - [Catchment rainfall discharge & TSS flux](#Catchment-rainfall-discharge-&-TSS-flux)\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b10aab-79f2-4aba-9373-d5146acc15a1",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This series of notebooks (`NSW DCCEEW training`) provides a demonstration of some basic analyses of water quality parameter (TSS) using Landsat data (Acolite processed).\n",
    "\n",
    "  - Demonstration notebooks\n",
    "    - For audience with various skills levels\n",
    "    - Get a feel for EASI / ADIAS and ODC technology\n",
    "  - Demonstrates some interesting science:\n",
    "    - Calculation of empirical algorithms for water quality parameters (TSS)\n",
    "    - Basic statistical and trends analyses\n",
    "    - Calculation of sediment flux using BoM rainfall data\n",
    "  - Touches on various technical aspects:\n",
    "    - JupyterLab environment and notebooks\n",
    "    - Data availability and access on ADIAS and elsewhere\n",
    "    - Visualisation\n",
    "    - Parallelism and parallelised processing\n",
    " \n",
    "# User parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5784ce77-0ee3-4d0a-897f-53ef41899b11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Selected river systems: lat/lon locations\n",
    "riv_loc =  (151.34428, -33.5677)   # selected location -- river mouth, Haweksbury\n",
    "\n",
    "min_longitude, max_longitude = (151.1355, 151.7047)   # ROI for visualisation purposes\n",
    "min_latitude, max_latitude = (-33.8025,-33.3707)\n",
    "\n",
    "time_range = ('2013-01-01','2025-01-01')   # selected time window: FULL LANDSAT TIME SERIES\n",
    "# time_range = ('2021-06-01','2022-06-01')   # selected time window: testing\n",
    "\n",
    "### Selected parameter to plot / visualise \n",
    "# Note: various WQ parameters can be theoretically selected for analysis in the code below. However,\n",
    "# the flux calculations at the end of this notebook will fail for WQ units other than 'mg/L'.\n",
    "WQparam = 'TSS'          # selected WQ parameter\n",
    "WQunits = 'mg/L'         # WQ units\n",
    "lower_is_better = True   # whether lower WQ values are blue/red in plots\n",
    "wq_log_scale = True      # whether to plot raw WQ values in log-scale\n",
    "\n",
    "n_workers = None    # for local Dask cluster\n",
    "# n_workers = 12; workers_mem = 8    # for Dask Gateway cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ee4795-02b4-4e3f-958e-c16421659f45",
   "metadata": {},
   "source": [
    "# Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8babf71a-bb0e-4785-af71-8382229915b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### System\n",
    "import sys, os\n",
    "import itertools\n",
    "\n",
    "### Data handling\n",
    "import pyproj\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from astropy.stats import sigma_clip\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import rioxarray\n",
    "import rasterio\n",
    "import rasterio.features\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "from shapely.affinity import translate\n",
    "from shapely.geometry import Polygon\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "### ODC / STAC\n",
    "import odc.stac\n",
    "import pystac_client\n",
    "\n",
    "### Data cube\n",
    "import datacube\n",
    "dc = datacube.Datacube(app=\"NSW_demo\")\n",
    "\n",
    "### Dask\n",
    "from dask.distributed import wait\n",
    "\n",
    "### Display / plots\n",
    "from IPython.core.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib.colors import LinearSegmentedColormap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561381a0-e7d7-4b55-8f30-48cff9e8bbde",
   "metadata": {},
   "source": [
    "Here making use of a couple of functions from the base EASI notebooks &ndash; these can be accessed by `git clone`-ing the following repo: `https://github.com/csiro-easi/easi-notebooks.git`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0934f4-5629-4577-86bf-e239d0217d99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Misc\n",
    "sys.path.append('/home/jovyan/git_hub_notebooks/scripts/')\n",
    "import notebook_utils   # for xarray_object_size(), localcluster_dashboard()\n",
    "from app_utils import display_map\n",
    "\n",
    "# Eric's own function for getting coastline data:\n",
    "exec(open(\"./get_coastline.py\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c6dce1-4e95-4f45-835f-58f4e5ecc4ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if lower_is_better: \n",
    "    cmap = 'jet'\n",
    "    cmap1 = 'RdBu_r'   # 'coolwarm': centre colour is grey -- 'RdBu_r': centre colour is white\n",
    "else: \n",
    "    cmap = 'jet_r'\n",
    "    cmap1 = 'RdBu'\n",
    "    \n",
    "if wq_log_scale: norm = colors.LogNorm()\n",
    "else: norm = None\n",
    "\n",
    "cmp = LinearSegmentedColormap.from_list(\"cmp\", [\"gainsboro\", \"gainsboro\"])   # \"dummy\" colormap for greyed out land pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46169b75-0ab3-4351-be1a-f625111f07e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "### Filter out following warnings:\n",
    "# /env/lib/python3.10/site-packages/distributed/client.py:3163: UserWarning: Sending large graph of size 32.04 MiB.\n",
    "# This may cause some slowdown. Consider scattering data ahead of time and using futures.\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "    \n",
    "# warnings.resetwarnings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a809983-6386-4116-87fa-a3e23eb3a477",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def mostcommon_crs_res(dc, query):\n",
    "    # Returns the most common CRS and resolution for a given DC query.\n",
    "    # Adapted from 'mostcommon_crs()' from 'notebook_utils'\n",
    "    \"\"\"Adapted from https://github.com/GeoscienceAustralia/dea-notebooks/blob/develop/Tools/dea_tools/datahandling.py\"\"\"\n",
    "    matching_datasets = dc.find_datasets(**query)\n",
    "    crs_list = [str(i.crs) for i in matching_datasets]\n",
    "    resx_list = [i.metadata_doc['grids']['default']['transform'][0] for i in matching_datasets]   # x-res\n",
    "    resy_list = [i.metadata_doc['grids']['default']['transform'][4] for i in matching_datasets]   # y-res\n",
    "    \n",
    "    crs_mostcommon = None\n",
    "    res_mostcommon = None\n",
    "    if len(crs_list) > 0:\n",
    "        # Identify most common CRS + resolution\n",
    "        crs_counts = Counter(crs_list)\n",
    "        crs_mostcommon = crs_counts.most_common(1)[0][0]\n",
    "        \n",
    "        resx_counts = Counter(resx_list)\n",
    "        resy_counts = Counter(resy_list)\n",
    "        res_mostcommon = (resx_counts.most_common(1)[0][0], resy_counts.most_common(1)[0][0])\n",
    "    else:\n",
    "        logger.warning('No data was found for the supplied product query')\n",
    "    return crs_mostcommon, res_mostcommon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220b43ff-49fe-4217-9c4d-e2d3767f3ec6",
   "metadata": {},
   "source": [
    "# Dask\n",
    "\n",
    "Flexible open-source library for parallel and distributed computing in Python. It provides integration with various Python libraries like NumPy, Pandas, and scikit-learn to enable parallel execution across multiple cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b2a68b-9fc7-457f-bab0-a4377a01ab65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Local Dask cluster\n",
    "if n_workers is None:  # local Dask cluster using all available CPUs\n",
    "    \n",
    "    from dask.distributed import Client, LocalCluster\n",
    "    # sys.path.append('/home/jovyan/git_hub_notebooks/scripts/')\n",
    "    # import notebook_utils   # for localcluster_dashboard()\n",
    "\n",
    "    cluster = LocalCluster()\n",
    "    client = Client(cluster)\n",
    "\n",
    "    print(f\"Local cluster dashboard: {notebook_utils.localcluster_dashboard(client,server='https://hub.adias.aquawatchaus.space')}\")\n",
    "    display(cluster)\n",
    "\n",
    "# cluster.close()\n",
    "# client.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726641d2-c033-46b6-9676-ac1f7721fb46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Dask Gateway cluster @ n_workers\n",
    "if n_workers is not None:\n",
    "\n",
    "    from dask_gateway import Gateway\n",
    "    gateway = Gateway()\n",
    "    \n",
    "    # shutdown_all_clusters...\n",
    "    clusterRpts = gateway.list_clusters()\n",
    "    if len(clusterRpts)>0: print(f\"Shutting down running clusters:\\n {clusterRpts}\")\n",
    "    for cluster in clusterRpts:\n",
    "        c = gateway.connect(cluster.name)\n",
    "        c.shutdown()\n",
    "\n",
    "    print(\"Creating new Gateway cluster...\")\n",
    "\n",
    "    options = gateway.cluster_options()\n",
    "    options.node_selection = \"worker\" \n",
    "    options.worker_cores = 8\n",
    "    options.worker_memory = workers_mem\n",
    "\n",
    "    cluster = gateway.new_cluster(cluster_options=options)\n",
    "    cluster.scale(n_workers)\n",
    "    display( cluster )\n",
    "\n",
    "    ### Wait for all workers to start\n",
    "    client = cluster.get_client()\n",
    "    display( client )\n",
    "    client.sync( client._wait_for_workers, n_workers=n_workers )\n",
    "\n",
    "# cluster.shutdown()\n",
    "# client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09126f14-de0b-46e0-a645-3191d38a8b9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_map(x=(min_longitude,max_longitude), y=(min_latitude,max_latitude))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b90c402-af66-4844-b631-6594c3837ff4",
   "metadata": {},
   "source": [
    "# Data loading, pre-processing, TSS calculation\n",
    "\n",
    "Refer to the first notebook in this series (`demo01`) for more info if needed!\n",
    "\n",
    "Overview of the Landsat data on ADS: https://explorer.adias.aquawatchaus.space/products/landsat8_c2_acolite_ar and https://explorer.adias.aquawatchaus.space/products/landsat9_c2_acolite_ar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcb1bb5-c821-475d-b2db-5ca32d729ba3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LS_band_aliases = ['SR_B1','SR_B3']\n",
    "chunking = {'x': 512, 'y': 512, 'time': 1}\n",
    "\n",
    "query = { 'product': ('landsat8_c2_acolite_ar','landsat9_c2_acolite_ar'),    # Landsat products\n",
    "          'longitude': (min_longitude, max_longitude),    # \"x\" axis bounds\n",
    "          'latitude': (min_latitude, max_latitude),      # \"y\" axis bounds\n",
    "          'time': time_range,                       # Any parsable date strings\n",
    "          'group_by': 'solar_day',                # Scene ordering\n",
    "          'measurements': LS_band_aliases }  # Landsat8/9 bands\n",
    "\n",
    "mc_crs, mc_res = mostcommon_crs_res(dc, query)   # Landsat datasets' native CRS and resolution\n",
    "query.update( output_crs=mc_crs, \n",
    "              dask_chunks=chunking, \n",
    "              resolution=mc_res,\n",
    "              resampling={'*':'average', 'l2_flags':'nearest'} )   # average resampling leads to least amount of missing pixels\n",
    "_ = query.pop('product')   # dc.load() not (supposed to be) able to load multiple products..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba80c323-e612-4a63-a626-7e050cddf8bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "data_ls8 = dc.load( product='landsat8_c2_acolite_ar', **query ).persist()\n",
    "_ = wait(data_ls8)\n",
    "\n",
    "data_ls9 = dc.load( product='landsat9_c2_acolite_ar', **query ).persist()\n",
    "_ = wait(data_ls9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a630ba-1176-4e68-b7c9-cee1a6aad10a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Merge LS8 and LS9 datasets\n",
    "data = xr.concat([data_ls8, data_ls9], dim=\"time\", compat='identical').sortby(\"time\").persist()\n",
    "_ = wait(data)\n",
    "\n",
    "### Apply conversion and empirical WQ algorithms.\n",
    "data = data * 1.0301 - 0.00001   # applied to each band\n",
    "data = data.where(data>0)   # filter out negative SR values\n",
    "\n",
    "data['TSS'] = 1.1486 * pow(data.SR_B3 / data.SR_B1, 0.7053)\n",
    "\n",
    "### Remove SR bands (not required any longer)\n",
    "data = data.drop(LS_band_aliases).persist()\n",
    "\n",
    "### Remove any time slice that only contains NaNs\n",
    "data = data.dropna('time',how='all').persist()\n",
    "_ = wait(data)\n",
    "\n",
    "tmp = data.time.values\n",
    "date_start = tmp[0].astype('datetime64[D]')\n",
    "date_end = tmp[-1].astype('datetime64[D]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7864b799-653f-49cf-b1f2-7e896bb93ca7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Generate coastline and land mask for current extents, in projected CRS\n",
    "tmp = data.TSS[0].rio.reproject('EPSG:4326').rename({'x':'longitude','y':'latitude'})\n",
    "\n",
    "offset = (-0.006,-0.001)   # fix apparent mis-alignment coastline vs. Landsat (...?!??)\n",
    "land_mask, shp_poly = get_coastline( ds_lon_vec=tmp.longitude.values, ds_lat_vec=tmp.latitude.values, offset=offset)   #, do_plot=True)#, buf=0.2 )\n",
    "\n",
    "land_mask.rio.write_crs('EPSG:4326', inplace=True)\n",
    "land_mask = land_mask.rio.reproject_match( data )\n",
    "shp_poly = shp_poly.set_crs('EPSG:4326').to_crs(mc_crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ef3f61-6695-43ab-a90f-4710e89fd8d7",
   "metadata": {},
   "source": [
    "# TSS flux using BoM rainfall\n",
    "\n",
    "Estimate quarterly TSS flux from BoM raifall over catchment, together with TSS estimates at the river mouth (from Landsat data).\n",
    "\n",
    "## Create mask of pixels in front of river mouth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dcbe74-f640-4d04-ae7b-349706957a8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Number of buffer pixels (Landsat resolution) for various masks\n",
    "n_pix_coast_buf = 8   # buffer around the coastline to be removed from above patch\n",
    "n_pix_dilation = 30   # to select a patch of water around the selected river mouth locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf496d7-f5c5-423f-91cb-0de65204c695",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Select the WQ of interest and re-chunk the Dask array -- remove time chunking for time-series processing\n",
    "data_wq = data['TSS'].persist()    #.chunk({'time':-1, 'x':32, 'y':32}).persist()   # DataArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8da2db-4f46-44a5-9e1b-b62f7ba53ca8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Reduce spatial compute requirements for demo\n",
    "tmp = data_wq[:,::3,::3].persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e16fe25-f8da-4dab-86a9-023f11c7b73a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "latlon_to_proj = pyproj.Transformer.from_crs(\"epsg:4326\", mc_crs, always_xy=True)   # transform to target proj\n",
    "\n",
    "### Binary image dilation function\n",
    "from scipy import ndimage\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "def expand_mask(mask_arr, npix, expand_true=True):\n",
    "    # Uses the True/False (masked/non-masked) values in the array 'mask_arr' and \n",
    "    # expands the True values spatially by 'npix' pixels. The value 'npix' can be\n",
    "    # non-integer, i.e. the mask can be expanded by any spatial distance.\n",
    "    # Originally expands True values (when expand_true=True). Can expand False \n",
    "    # values by setting expand_true=False.\n",
    "    nmid = np.floor(npix)\n",
    "    nmax = int( nmid*2 + 1 )\n",
    "    struc = np.zeros((nmax, nmax), dtype='bool')\n",
    "    for ii in range(nmax):   # create desired binary structure for morphological operation\n",
    "        for jj in range(ii,nmax):\n",
    "            if pdist( [[nmid,nmid], [ii,jj]] ) <= npix:\n",
    "                struc[ii,jj] = True\n",
    "                struc[jj,ii] = True\n",
    "    if expand_true:\n",
    "        return ndimage.binary_dilation(mask_arr, structure=struc)\n",
    "    else:\n",
    "        return ~ndimage.binary_dilation(~mask_arr.astype(bool), structure=struc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209ee1d3-b390-4f1f-93b8-a124f79c6842",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### ROI mask & example of resulting TSS map (overall mean)\n",
    "mask = xr.full_like(tmp[0],0.0).compute().copy()\n",
    "\n",
    "### Initialise seed pixel at river loc\n",
    "px, py = latlon_to_proj.transform(riv_loc[0], riv_loc[1])\n",
    "xind = np.argmin(abs(mask.x-px).values)\n",
    "yind = np.argmin(abs(mask.y-py).values)\n",
    "mask[yind,xind] = 1.0\n",
    "\n",
    "### Expand mask by selected nr of pixels ... somewhat time and MEM consuming\n",
    "mask2 = expand_mask(mask.values, n_pix_dilation, expand_true=True)\n",
    "mask.data = mask2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58f2fb2-cd97-4302-8a70-ce0029cceccd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Generate coastline and land mask for current extents, in projected CRS\n",
    "ctmp = tmp[0].rio.reproject('EPSG:4326').rename({'x':'longitude','y':'latitude'})\n",
    "\n",
    "offset = (-0.006,-0.001)   # fix apparent mis-alignment coastline vs. Landsat\n",
    "cland_mask, cshp_poly = get_coastline( ds_lon_vec=ctmp.longitude.values, ds_lat_vec=ctmp.latitude.values, offset=offset)   #, do_plot=True)#, buf=0.2 )\n",
    "\n",
    "cland_mask.rio.write_crs('EPSG:4326', inplace=True)\n",
    "cland_mask = cland_mask.rio.reproject_match( tmp )\n",
    "cshp_poly = cshp_poly.set_crs('EPSG:4326').to_crs(mc_crs)\n",
    "\n",
    "cland_mask = cland_mask.where(~cland_mask.isnull(),0).astype('bool')\n",
    "mask2 = expand_mask(cland_mask, n_pix_coast_buf, expand_true=True)\n",
    "cland_mask.data = mask2\n",
    "\n",
    "### Combine river mouth area mask and coast mask\n",
    "mask = mask.where(~cland_mask,0)\n",
    "\n",
    "### Mask WQ time series data\n",
    "data_msk = tmp.where(mask).dropna('time',how='all')\n",
    "data_msk = data_msk.persist()\n",
    "_ = wait(data_msk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd28785-79ca-414f-ad53-9caade65b236",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Plots\n",
    "fig, (ax1,ax2) = plt.subplots(1, 2, figsize=(16,5))\n",
    "\n",
    "mask.plot(ax=ax1, cbar_kwargs={'label':'mask'})\n",
    "shp_poly.boundary.plot(ax=ax1, color='grey')\n",
    "ax1.set_title(f\"River mouth mask\")\n",
    "ax1.set_aspect('equal','box')\n",
    "\n",
    "### Example plot for selected param\n",
    "data_msk.mean('time').plot(robust=True, cmap=cmap, cbar_kwargs={'label':f'{WQparam} [{WQunits}]'}, ax=ax2)   #, norm=norm)\n",
    "shp_poly.boundary.plot(ax=ax2, color='grey')\n",
    "ax2.set_title(f\"Overall mean of {WQparam}\")\n",
    "ax2.set_aspect('equal','box')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2acfa3-6ebe-4898-a5b8-e5bb11ebf2f9",
   "metadata": {},
   "source": [
    "## Spatial TSS statistics at river mouth\n",
    "\n",
    "Quarterly median & IQR, min & max of the WQ parameter: here we derive the statistics of interest over all valid pixels spatially (within AOI), and temporally within quarters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367455a9-7e64-4b30-8977-542d8000ff70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_msk = data_msk.chunk({'x':128,'y':128})\n",
    "data_msk = data_msk.dropna('time',how='all').persist()  # remove empty time slices\n",
    "_ = wait(data_msk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7205b4f-0f54-48e4-a432-cf6476159ba6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def qntle_fcn(ds, qnt):\n",
    "    tmp = ds.chunk({'x':-1, 'y':-1, 'time':-1}).quantile(q=qnt, dim=['x','y','time'])\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b49658c-5408-4e4c-9034-6409b7ce7e80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Min, max, median + IQR calculations\n",
    "WQlow_quart = data_msk.resample(time=\"QS\",skipna=True).map(qntle_fcn,qnt=0.25).persist()\n",
    "WQupp_quart = data_msk.resample(time=\"QS\",skipna=True).map(qntle_fcn,qnt=0.75).persist()\n",
    "WQmed_quart = data_msk.resample(time=\"QS\",skipna=True).map(qntle_fcn,qnt=0.5).persist()\n",
    "WQmin_quart = data_msk.resample(time=\"QS\",skipna=True).min().min(['x','y']).persist()\n",
    "WQmax_quart = data_msk.resample(time=\"QS\",skipna=True).max().max(['x','y']).persist()\n",
    "_ = wait(WQmax_quart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e05067-e4a3-4a40-ae73-135698c2ddd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,5))\n",
    "plt.plot(WQmed_quart.time, WQmed_quart, label='median')\n",
    "plt.gca().plot(WQlow_quart.time, WQlow_quart,color='grey', ls=':', label='IQR')\n",
    "plt.gca().plot(WQupp_quart.time, WQupp_quart,color='grey', ls=':')\n",
    "plt.gca().plot(WQmin_quart.time, WQmin_quart,color='green', label='min/max')\n",
    "plt.gca().plot(WQmax_quart.time, WQmax_quart,color='green')\n",
    "plt.gca().set_yscale('log'); plt.gca().legend(); plt.gca().set_title(f'Quarterly TSS at river mouth')\n",
    "plt.gca().set_xlabel('time'); plt.gca().set_ylabel('TSS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b772684-6e2f-4254-a583-6e6326506faa",
   "metadata": {},
   "source": [
    "## Load catchment shape file\n",
    "\n",
    "We need the boundaries of each catchment of interest for the purpose of deriving the catchments' rainfall discharge.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b034e88-9c24-4a3c-9077-fa1d2083ea06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "buf_deg = 0.1   # lat/lon buffer around catchment (mainly for visualisation)\n",
    "sname_list = [['hawkesbury','cowan','pittwater','brisbane']]   # sub-catchments corresponding to the above river systems (search names in catchment shape file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfdffa1-db40-4c4c-a0f9-8d379b7f3cf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Load MAIN catchment shape file, extract desired polygons\n",
    "shp_file = \"./ancillary_data/EstCatch/EstEdit2.shp\"   # MAIN catchments\n",
    "\n",
    "catch_shp_list = []\n",
    "for sname in sname_list:\n",
    "    shp = gpd.read_file( shp_file ).to_crs('epsg:4326')\n",
    "\n",
    "    drop_list = []\n",
    "    for ff in shp.iterrows():\n",
    "        tmp = ff[1].CATCHMENTN\n",
    "        foo = [sn in tmp.lower() for sn in sname if tmp is not None]\n",
    "        if not any(foo): drop_list.append( ff[0] )\n",
    "\n",
    "    shp.drop( drop_list, inplace=True )   # remove polygons\n",
    "    catch_shp_list.append(shp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89114a59-fc98-40bc-8d36-cf97c0efc0bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Extract selected catchment's bounding box\n",
    "bbox_list = []\n",
    "\n",
    "for shp in catch_shp_list:\n",
    "    tmp = shp.bounds   # DataFrame with columns minx, miny, maxx, maxy values containing the bounds for each geometry\n",
    "    xmin = min(tmp.minx)\n",
    "    xmax = max(tmp.maxx)\n",
    "    ymin = min(tmp.miny)\n",
    "    ymax = max(tmp.maxy)\n",
    "\n",
    "    bbox = (xmin-buf_deg, ymin-buf_deg, xmax+buf_deg, ymax+buf_deg)   # polygon boundary\n",
    "    bbox_list.append(bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc09ede-e9ef-45bb-9bfd-11e70bbd025c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "land_mask2, shp_poly2 = get_coastline( ds_lon_vec=[bbox[0],bbox[2]], ds_lat_vec=[bbox[1],bbox[3]], offset=offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9677105c-67b7-40fc-b8af-d632be7e241d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Plots\n",
    "for ii,catch in enumerate(catch_shp_list):\n",
    "    bbox = bbox_list[ii]\n",
    "    catch.boundary.plot(ax=plt.gca(), color='green')\n",
    "    shp_poly2.boundary.plot(ax=plt.gca(), color='grey')\n",
    "    plt.gca().set_xlim((bbox[0],bbox[2]))\n",
    "    plt.gca().set_ylim((bbox[1],bbox[3]))\n",
    "    plt.xlabel(\"longitude\"); plt.ylabel(\"latitude\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e88e5c6-8b48-41ac-b03b-563646eda5d3",
   "metadata": {},
   "source": [
    "## BOM rainfall\n",
    "\n",
    "Can access a variety of datasets hosted outside the current (ADIAS) EASI deployment:\n",
    "  - DEA, e.g. fractional cover, landcover, etc.\n",
    "  - IMOS, e.g. currents\n",
    "  - Other EASI deployments, e.g. BoM rainfall, other satellite datasets, etc.\n",
    "  - Raster and <i>in-situ</i> datasets\n",
    "  - etc.\n",
    "\n",
    "The BOM rainfall dataset used below can be accessed through the explorer's STAC API of the CSIRO EASI deployment (Sydney).\n",
    "\n",
    "https://explorer.csiro.easi-eo.solutions/products/agcd_rain_recal_day -- DAY dataset  \n",
    "https://explorer.csiro.easi-eo.solutions/products/agcd_rain_total_month -- MONTH dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c663cd2c-b5bf-4c28-bbec-f7921d02fa78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bom_start_date = data_msk.time[0].values.astype(str)[:10]   \n",
    "bom_end_date = data_msk.time[-1].values.astype(str)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8753f9a-f8a7-4839-94ab-ca74fbe2f445",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "time_chunk = 8\n",
    "\n",
    "### Get the rainfall data:\n",
    "catalog = pystac_client.Client.open(\"https://explorer.csiro.easi-eo.solutions/stac\")\n",
    "\n",
    "query = catalog.search( collections=['agcd_rain_total_month'], datetime=f\"{bom_start_date}/{bom_end_date}\", max_items=None )\n",
    "\n",
    "rain_ds = odc.stac.load( query.items(), bbox=bbox, chunks={'longitude': 512, 'latitude': 512, 'time': time_chunk} ).persist()\n",
    "_ = wait(rain_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697d9c0c-235e-4da8-b5ae-c69c50d9e7b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f'BoM rainfall GeoTransform: [{rain_ds.spatial_ref.GeoTransform}]')\n",
    "display(rain_ds)\n",
    "rain_ds.rain_total[:5].plot(figsize=(16,3.5), col='time', robust=True, col_wrap=5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c09b93-fa1a-49a1-bad2-c5f25afdbe44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print( f\"Rainfall dataset has {rain_ds.sizes['time']} time slices from {rain_ds.time[0].dt.date.values} to {rain_ds.time[-1].dt.date.values}.\" )\n",
    "print( f\"Rainfall {notebook_utils.xarray_object_size(rain_ds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ec23ea-d68d-485e-bc4a-505e8cf86600",
   "metadata": {},
   "source": [
    "## Catchment 'cookie-cutting'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f652b5dd-c187-4db0-8169-2bdf6c18f880",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Create raster mask from catchment polygon\n",
    "geotx = [float(vv) for vv in rain_ds.spatial_ref.GeoTransform.split()]\n",
    "geotx = [geotx[1], geotx[2], geotx[0], geotx[4], geotx[5], geotx[3]]\n",
    "aff = rasterio.Affine( *geotx )\n",
    "\n",
    "mask = rasterio.features.rasterize( ((feat['geometry'], 1) for feat in catch.iterfeatures()),\n",
    "                                    out_shape = (rain_ds.dims['latitude'],rain_ds.dims['longitude']),\n",
    "                                    transform = aff )\n",
    "mask = xr.DataArray(mask, coords=(rain_ds.latitude, rain_ds.longitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c350b1-ffe6-4a48-b3e1-65d74aabfe29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rain_ds = rain_ds.where(mask)   # cookie-cutting to catchment boundaries..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f92a8e9-80a7-49bb-bdb0-39f9e46007ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Plot\n",
    "tmp = np.linspace(1, rain_ds.sizes['time'], 6, dtype='int') - 1   # select a few time indices for plotting\n",
    "pp = rain_ds.rain_total[tmp].plot(figsize=(16,8), col='time', robust=True, col_wrap = 3)\n",
    "\n",
    "for ax in pp.axs.flat:\n",
    "    catch.boundary.plot(ax=ax, color='black', linewidth=1)\n",
    "    shp_poly2.boundary.plot(ax=ax, color='grey', linewidth=1)\n",
    "    plt.gca().set_xlim((bbox[0],bbox[2]))\n",
    "    plt.gca().set_ylim((bbox[1],bbox[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bce5c0-fe92-4498-861d-eebf3077ca8c",
   "metadata": {},
   "source": [
    "## Catchment rainfall discharge & TSS flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09475aa-f2a5-41ae-9459-d18cdecd90d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "latlon_to_alb = pyproj.Transformer.from_crs(\"epsg:4326\", \"epsg:3577\", always_xy=True)   # transform to equal-area Albers\n",
    "\n",
    "def PolyArea(x,y):\n",
    "    # Surface area of a polygon with 'x' and 'y' coordinates (vertices).\n",
    "    # https://en.wikipedia.org/wiki/Shoelace_formula\n",
    "    return 0.5*np.abs(np.dot(x,np.roll(y,1))-np.dot(y,np.roll(x,1)))\n",
    "\n",
    "pix_areas = mask.copy(deep=True).astype(float)\n",
    "xres = abs(pix_areas.rio.resolution()[0])\n",
    "yres = abs(pix_areas.rio.resolution()[1])\n",
    "\n",
    "### Pix area in m^2 for each pixel\n",
    "# Note: 0.05 x 0.05 deg pixel located at a latitude of about 23 degrees is about 26,832,000 square meters...\n",
    "for lonind,latind in itertools.product(range(pix_areas.sizes['longitude']), range(pix_areas.sizes['latitude'])):\n",
    "    if pix_areas[latind,lonind]==0: \n",
    "        pix_areas[latind,lonind] = np.nan\n",
    "        continue    \n",
    "\n",
    "    xmin = pix_areas.longitude[lonind].values\n",
    "    xmax = xmin + xres\n",
    "    ymin = pix_areas.latitude[latind].values\n",
    "    ymax = ymin + yres\n",
    "\n",
    "    pxvec, pyvec = latlon_to_alb.transform([xmin, xmin, xmax, xmax],[ymin, ymax, ymax, ymin])\n",
    "    pix_areas[latind,lonind] = PolyArea(pxvec,pyvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e46059-aa31-47fb-b44d-52e2d8ed91d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert WQunits=='mg/L', \"Code below cannot handle selected WQ units.\"\n",
    "\n",
    "### Selected flux units\n",
    "mg_per_XX = 1_000_000_000_000; flux_units = 'kt/quarter'          # mg_per_kt\n",
    "# mg_per_XX = 1_000_000_000_000_000; flux_units = 'Mt/quarter'      # mg_per_Mt\n",
    "# mg_per_XX = 1_000_000_000_000_000_000; flux_units = 'Gt/quarter'  # mg_per_Gt\n",
    "\n",
    "### Spatial & temporal (quarterly) aggregation of catchment rainfall ---> total catchment discharge volume in L (in each quarter)\n",
    "### Apply pix area to rainfall data --> catchment rainfall runoff (river runoff) in [L/mth]\n",
    "disch_vol_quart = (0.6 * rain_ds * pix_areas).rain_total.resample(time=\"QS\",skipna=True).sum().sum(['latitude','longitude'])\n",
    "assert np.all(WQmed_quart[1:].time.values==disch_vol_quart.time.values), f\"Different TS dates.\"\n",
    "\n",
    "### Flux\n",
    "flux_low_quart = WQlow_quart[1:] * disch_vol_quart / mg_per_XX   # mg/L * L * Mt/mg\n",
    "flux_upp_quart = WQupp_quart[1:] * disch_vol_quart / mg_per_XX\n",
    "flux_med_quart = WQmed_quart[1:] * disch_vol_quart / mg_per_XX\n",
    "flux_min_quart = WQmin_quart[1:] * disch_vol_quart / mg_per_XX\n",
    "flux_max_quart = WQmax_quart[1:] * disch_vol_quart / mg_per_XX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74870f3-c46f-45f1-bb67-6766941ff4a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.subplots(figsize=(24,4))\n",
    "cols = 'cornflowerblue'   # ['yellowgreen','orange','cornflowerblue']\n",
    "bw = 0.6   # bar width\n",
    "\n",
    "fqlo = flux_low_quart.values\n",
    "fqup = flux_upp_quart.values\n",
    "fmed = flux_med_quart.values\n",
    "fmin = flux_min_quart.values\n",
    "fmax = flux_max_quart.values\n",
    "\n",
    "yr = [str(tt) for tt in flux_low_quart.time.dt.year.values]\n",
    "qr = [str(tt) for tt in flux_low_quart.time.dt.quarter.values]\n",
    "tlab = [yy+'_Q'+qq for (yy,qq) in zip(yr,qr)]\n",
    "tvec = np.arange(len(tlab))\n",
    "\n",
    "plt.bar(tvec, fmax, color=cols, width=bw, alpha=0.2)\n",
    "plt.bar(tvec, fmed, color=cols, width=bw, alpha=0.5, yerr=np.vstack((fmed-fqlo,fqup-fmed)), ecolor='grey')\n",
    "plt.bar(tvec, fmin, color=cols, width=bw, alpha=0.9)\n",
    "plt.gca().set_yscale('log')\n",
    "plt.xticks(tvec, tlab, rotation=35)\n",
    "plt.xlabel('time')\n",
    "plt.ylabel(f'{WQparam} flux [{flux_units}]')\n",
    "plt.margins(x=0.01)\n",
    "\n",
    "plt.title(f'{WQparam} flux: minimum + median + maximum values (bars) & inter-quartile range (error bars)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad12164-cd62-494a-b8df-a02c3172cfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "if n_workers is None:  # local Dask cluster\n",
    "    cluster.close()\n",
    "    client.shutdown()\n",
    "else:   # Gateway cluster\n",
    "    cluster.shutdown()\n",
    "    client.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9457594-1e2e-4982-95c7-132d58e0969e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### End notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
