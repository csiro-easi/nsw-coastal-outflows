{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a811095a-e768-4d0a-92dd-da92b7baa903",
   "metadata": {},
   "source": [
    "# <u>NSW DCCEEW training &ndash; Demo 6: external data access</u>\n",
    "\n",
    " - <b>Author</b>: Eric.Lehmann@csiro.au\n",
    " - <b>Release date / version</b>: Aug. 2024, v1.0\n",
    " - <b>Dev. platform</b>: CSIRO ADIAS/ADS (hub.adias.aquawatchaus.space)\n",
    " - <b>Server profile</b>: EASI Open Data Cube No ML &ndash; Version 2023.10.2 \n",
    " - <b>Server resources</b>: 32 CPU &ndash; 64GB RAM\n",
    " - <b>Python kernel</b>: `Python 3 (ipykernel)`\n",
    " - <b>Dask</b>: Local cluster\n",
    "  \n",
    "# Overview\n",
    "\n",
    "Demonstrates how to access datasets that are 'external' to the current EASI deployment, e.g. from IMOS, other EASI deployments, DEA, BoM, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5573c169-aae7-466f-980d-f4fcc55d6a49",
   "metadata": {},
   "source": [
    "# User parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea187e6-a0a8-4636-82df-cc861f7dc4f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set a bounding box [xmin, ymin, xmax, ymax] in latitude and longitude\n",
    "min_lat, max_lat = (-34.6919, -33.2479)   # Sydney coastal\n",
    "min_lon, max_lon = (150.7159, 152.0508)\n",
    "buf = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20542c2d-05e2-4a43-9e17-d0c89f53a112",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# selected year -- for NRT product\n",
    "selected_year = 2024\n",
    "\n",
    "n_workers = None    # for local Dask cluster\n",
    "# n_workers = 12; workers_mem = 8    # for Dask Gateway cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fb1e0e-d425-41ff-ab25-588c74827bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_lat = min_lat - buf\n",
    "max_lat = max_lat + buf\n",
    "min_lon = min_lon - buf\n",
    "max_lon = max_lon + buf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba63d69-f66a-4abc-a7e3-20da8d8d0f4a",
   "metadata": {},
   "source": [
    "# Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d06610-3942-4f7b-aa41-914a938264f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sys, io\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from siphon.catalog import TDSCatalog\n",
    "from IPython.core.display import HTML\n",
    "# import cmocean.cm as cmo\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "from dask.distributed import wait   # , progress\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "# from: https://github.com/csiro-easi/easi-notebooks.git\n",
    "sys.path.append('/home/jovyan/git_hub_notebooks/scripts/')\n",
    "import notebook_utils   # for xarray_object_size(), localcluster_dashboard()\n",
    "from app_utils import display_map\n",
    "\n",
    "# Eric's own function for getting coastline data:\n",
    "exec(open(\"./get_coastline.py\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e86752-2e37-4d2c-ab0e-3a0a6f93e08f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "### Filter out following warnings:\n",
    "# /env/lib/python3.10/site-packages/distributed/client.py:3163: UserWarning: Sending large graph of size 32.04 MiB.\n",
    "# This may cause some slowdown. Consider scattering data ahead of time and using futures.\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# warnings.resetwarnings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36247a2b-949e-41ee-9a5e-5a926d2421b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Misc.\n",
    "cmp = mcolors.LinearSegmentedColormap.from_list(\"cmp\", [\"gainsboro\", \"gainsboro\"])   # \"dummy\" colormap for greyed out land pixels\n",
    "\n",
    "# Function to create truncated colormap\n",
    "def truncate_colormap(cmap, minval=0.25, maxval=0.75, n=100):\n",
    "    new_cmap = mcolors.LinearSegmentedColormap.from_list(\n",
    "        'truncated_' + cmap.name, cmap(np.linspace(minval, maxval, n)))\n",
    "    return new_cmap\n",
    "\n",
    "jett = truncate_colormap(plt.cm.jet)   # truncated 'jet' colormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b2a68b-9fc7-457f-bab0-a4377a01ab65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Local Dask cluster\n",
    "if n_workers is None:  # local Dask cluster using all available CPUs\n",
    "    \n",
    "    from dask.distributed import Client, LocalCluster\n",
    "    # sys.path.append('/home/jovyan/git_hub_notebooks/scripts/')\n",
    "    # import notebook_utils   # for localcluster_dashboard()\n",
    "\n",
    "    cluster = LocalCluster()\n",
    "    client = Client(cluster)\n",
    "\n",
    "    print(f\"Local cluster dashboard: {notebook_utils.localcluster_dashboard(client,server='https://hub.adias.aquawatchaus.space')}\")\n",
    "    display(cluster)\n",
    "\n",
    "### Use the following to shut down this cluster:\n",
    "# cluster.close()\n",
    "# client.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726641d2-c033-46b6-9676-ac1f7721fb46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Dask Gateway cluster @ n_workers\n",
    "if n_workers is not None:\n",
    "\n",
    "    from dask_gateway import Gateway\n",
    "    gateway = Gateway()\n",
    "    \n",
    "    # shutdown_all_clusters...\n",
    "    clusterRpts = gateway.list_clusters()\n",
    "    if len(clusterRpts)>0: print(f\"Shutting down running clusters:\\n {clusterRpts}\")\n",
    "    for cluster in clusterRpts:\n",
    "        c = gateway.connect(cluster.name)\n",
    "        c.shutdown()\n",
    "\n",
    "    print(\"Creating new Gateway cluster...\")\n",
    "\n",
    "    options = gateway.cluster_options()\n",
    "    options.node_selection = \"worker\" \n",
    "    options.worker_cores = 8\n",
    "    options.worker_memory = workers_mem\n",
    "\n",
    "    cluster = gateway.new_cluster(cluster_options=options)\n",
    "    cluster.scale(n_workers)\n",
    "    display( cluster )\n",
    "\n",
    "    ### Wait for all workers to start\n",
    "    client = cluster.get_client()\n",
    "    display( client )\n",
    "    client.sync( client._wait_for_workers, n_workers=n_workers )\n",
    "\n",
    "### Use the following to shut down this cluster:\n",
    "# cluster.shutdown()\n",
    "# client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f3491e-1682-4ba4-a15c-1bf6177f55c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_map(x=(min_lon,max_lon), y=(min_lat,max_lat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182a9455-c31c-4cb7-9afc-e6ab49564c75",
   "metadata": {},
   "source": [
    "# Access IMOS Global Sea Level data via thredds service\n",
    "\n",
    "Demonstrates how to access and load the IMOS - OceanCurrent - Gridded sea level anomaly (GSLA) dataset: https://oceancurrent.aodn.org.au/product.php or https://portal.aodn.org.au/search > Physical Water > Current, or [here](https://catalogue-imos.aodn.org.au/geonetwork/srv/eng/catalog.search#/metadata/0c9eb39c-9cbe-4c6a-8a10-5867087e703a)\n",
    "\n",
    "Thredds catalog for this product (NRT, available to 2011 &ndash; 2024; vs. DM, delayed mode, 1993 &ndash; 2020 only): https://thredds.aodn.org.au/thredds/catalog/IMOS/OceanCurrent/GSLA/NRT/catalog.html. Here only using a few dates in a given / selected year for illustration purposes.\n",
    "\n",
    "This is a daily dataset, seemingly with 0.2 x 0.2 deg resolution. Example of how to access this data [here](https://github.com/aodn/imos-user-code-library/blob/master/Python/notebooks/SAR_winds/SAR_winds_getting_started_jupyter_notebook/ausar_winds_getting_started_notebook.ipynb).\n",
    "\n",
    "The code below accesses the IMOS data via the thredds service though other potential ways of accessing this data could be used, including from an S3 bucket of IMOS data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f9f9be-999d-4839-88d0-7e8c0b86886d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_url = f\"https://thredds.aodn.org.au/thredds/catalog/IMOS/OceanCurrent/GSLA/NRT/{selected_year}/catalog.xml\"\n",
    "cat = TDSCatalog(cat_url)   # connect to the Thredds database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b249797-31f4-4ee2-a873-016397dc50d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Show the first few datasets / dates:\n",
    "cat.datasets[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffa0a0d-5a31-4036-9667-dbbcf0008ad5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "num_dsets = 20   # number of datasets / dates to download (for illustration purposes)\n",
    "\n",
    "# This executes the data download SERIALLY! (FOR-loop) I.e. the data is downloaded in the workers' memory but\n",
    "# each date is downloaded one after the other (not in parallel)\n",
    "dsets = []\n",
    "for cds in cat.datasets[:num_dsets]:\n",
    "    tmp = cds.remote_access(use_xarray=True)   # Open the remote dataset and get a netCDF4-compatible `Dataset` object providing index-based subsetting capabilities\n",
    "    dsets.append( tmp.drop_vars(['start_time','end_time','UCUR','VCUR','UCUR_MEAN','VCUR_MEAN'])\n",
    "                     .sel(LONGITUDE=slice(min_lon,max_lon), LATITUDE=slice(min_lat,max_lat))\n",
    "                     .chunk('auto').persist() )\n",
    "dsets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febc009f-8464-4bff-a25e-88d499826481",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(dsets[0].GSLA.attrs['standard_name'])\n",
    "dsets[0].GSLA.attrs['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c923951a-4f34-4e09-bc13-a1cf408e1812",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(dsets[0].GSL.attrs['standard_name'])\n",
    "dsets[0].GSL.attrs['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52aad187-6274-4388-a7fd-f60d6aa89cb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Concatenate all dates into single object\n",
    "ds_subs = xr.concat(dsets, dim='TIME').sortby('TIME').persist()\n",
    "display(ds_subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed500909-11ff-4daa-a512-3a1584730d7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Generate coastline and land mask for current dataset\n",
    "land_mask, shp_poly = get_coastline( ds_lon_vec=ds_subs.LONGITUDE.values.copy(),\n",
    "                                     ds_lat_vec=ds_subs.LATITUDE.values.copy(), buf=0.2 ) #, verbose=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30054ac-7160-4fea-951e-a1722e95197a",
   "metadata": {},
   "source": [
    "## Time index issue\n",
    "\n",
    "There appears to be multiple repeats of some dates along the time series... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76758a19-805b-408c-850d-e51ea4992770",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diffvec = np.diff( ds_subs.TIME ) / np.timedelta64(1, 'D')\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(1, 2, figsize=(16,5))\n",
    "\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "ax1.plot( ds_subs.TIME[1:], diffvec )\n",
    "ax1.set_ylabel('days'); ax1.set_title('Nr of days between consecutive time slices, vs. time')\n",
    "\n",
    "ax2.plot(ds_subs.TIME)\n",
    "ax2.set_ylabel('index'); ax2.set_title('Date vs. time index');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440d23c2-18fc-4328-9503-85ad73b5420f",
   "metadata": {},
   "source": [
    "We need to ensure that the dataset has only one time slice per day, so let's group the time slices by days and then combine the multiple-day data using `mean`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdc1e70-63d0-491a-842a-83f01b48fa30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_subs = ds_subs.resample(TIME='1D').mean('TIME').persist()\n",
    "display(ds_subs)\n",
    "_ = wait(ds_subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df6fff8-e75d-4b04-ab49-f30e6bb65193",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diffvec = np.diff( ds_subs.TIME ) / np.timedelta64(1, 'D')\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(1, 2, figsize=(16,5))\n",
    "\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "ax1.plot( ds_subs.TIME[1:], diffvec )\n",
    "ax1.set_ylabel('days'); ax1.set_title('Nr of days between consecutive time slices, vs. time')\n",
    "\n",
    "ax2.plot(ds_subs.TIME)\n",
    "ax2.set_ylabel('index'); ax2.set_title('Date vs. time index');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8bb98c-fbec-47bb-8485-b5b693671fa8",
   "metadata": {},
   "source": [
    "## Demo plots for selected year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0226f636-92b9-4d1e-8a3e-ce8db29e2816",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### GSL plots\n",
    "display(HTML('<h3>Sea level plots'))\n",
    "plt_ind = np.linspace(2, ds_subs.sizes['TIME'], 6, dtype='int') - 1   # some selected time slices to display\n",
    "pp = ds_subs.GSL[plt_ind,:,:].plot( col='TIME', col_wrap=3, figsize=(18,8), \n",
    "                                    cbar_kwargs={'label': ds_subs.GSL.attrs['standard_name']} )\n",
    "for ii,ax in enumerate(pp.axs.flat):\n",
    "    ax.set_aspect('equal','box')\n",
    "    land_mask.plot(ax=ax, add_colorbar=False, add_labels=False, cmap=cmp)\n",
    "    shp_poly.boundary.plot(ax=ax, color='black', linewidth=1);\n",
    "plt.show()\n",
    "\n",
    "### GSLA plots\n",
    "display(HTML('<h3>Sea level anomaly plots'))\n",
    "plt_ind = np.linspace(2, ds_subs.sizes['TIME'], 6, dtype='int') - 1   # some selected time slices to display\n",
    "pp = ds_subs.GSLA[plt_ind,:,:].plot( col='TIME', col_wrap=3, figsize=(18,8), center=False,\n",
    "                                     cbar_kwargs={'label': ds_subs.GSLA.attrs['standard_name']} )\n",
    "for ii,ax in enumerate(pp.axs.flat):\n",
    "    ax.set_aspect('equal','box')\n",
    "    land_mask.plot(ax=ax, add_colorbar=False, add_labels=False, cmap=cmp)\n",
    "    shp_poly.boundary.plot(ax=ax, color='black', linewidth=1);    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2286eb2e-c0cf-40c8-bb8e-a9d624c6192e",
   "metadata": {},
   "source": [
    "# Access CCMP wind data via http access\n",
    "\n",
    "## Overview\n",
    "\n",
    "Demonstrates how to access and load the Cross-Calibrated Multi-Platform (CCMP) Wind Vector Analysis Product v3.1 dataset: https://www.remss.com/measurements/ccmp/ (or https://www.remss.com/measurements/wind/)\n",
    "\n",
    "HTTP data access for this product [here](https://data.remss.com/ccmp/v03.1/).\n",
    "\n",
    "This is a <b>4-times-daily</b> dataset (every 6 hours), from Jan. 1993 to Jan. 2024, with 0.25 x 0.25 deg resolution. Here demonstrated for one selected month of one selected year.\n",
    "\n",
    "Please note the following specific warning from the [Remote Sensing Systems](https://www.remss.com/measurements/ccmp/) website:\n",
    "\n",
    "> The L4.0 CCMP V3.1 products consist of daily files containing four daily maps (00, 06, 12, and 18Z) of each variable. The files are in netCDF-4 format with CF-1.8 compliant metadata. Note that winds are provided for both ocean and land regions. The winds over land are from ERA5 but were subjected to the same adjustments as the oceanic winds which are unlikely to be correct for land surfaces. <b>Therefore, we do not recommend using winds over land.</b>\n",
    "\n",
    "Further wind datasets could potentially also be sourced from here: https://www.ospo.noaa.gov/Products/atmosphere/wind.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aa5a8e-ff34-40e2-b8e5-4da4483db4de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_year = '2024'\n",
    "selected_month = '03'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1da8ff0-51e3-4abc-a42c-cc73550bff50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Function to recursively crawl through dataset's URL tree\n",
    "\n",
    "def list_nc_files(url, verbose=False):\n",
    "    nc_files = []\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        links = soup.find_all('a')\n",
    "        for link in links:\n",
    "            href = link.get('href')\n",
    "            if 'To Parent Directory' in link.contents[0]:\n",
    "                pass\n",
    "            elif href.endswith('.nc') and 'monthly_mean' not in href:\n",
    "                tmp = urljoin(url, href)\n",
    "                if verbose: print(tmp)\n",
    "                nc_files.append(tmp)\n",
    "            elif href.endswith('/'):\n",
    "                tmp = list_nc_files(urljoin(url, href))\n",
    "                [nc_files.append(ii) for ii in tmp]   # unlist elements of subdirectory\n",
    "                \n",
    "    return nc_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440d72dd-9a89-4140-8225-a4f7c8fc73f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### URL of desired product:\n",
    "url = f\"https://data.remss.com/ccmp/v03.1/Y{selected_year}/M{selected_month}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b23f035-ac73-4240-9a2c-338bc22253d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nc_files = list_nc_files(url, verbose=False)\n",
    "\n",
    "print(f'Total of {len(nc_files)} .nc files...')\n",
    "nc_files[:10]   # some selected files / dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15d5ec3-f378-4a63-ad9a-b553065b88c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Investigate one of the datasets\n",
    "nc_content = requests.get(nc_files[0]).content\n",
    "ds = xr.open_dataset( io.BytesIO(nc_content), drop_variables='nobs' )   # open the file from memory using xarray\n",
    "display(ds)\n",
    "ds.uwnd[0].plot(robust=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a337a4-9489-4a0b-963c-549483e20963",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# This executes the data download SERIALLY! (FOR-loop)\n",
    "dsets = []\n",
    "for ff in nc_files:\n",
    "    resp = requests.get(ff)\n",
    "    nc_content = resp.content\n",
    "\n",
    "    # Open the file from memory using xarray\n",
    "    ds = xr.open_dataset( io.BytesIO(nc_content), drop_variables='nobs' )\n",
    "    ds = ds.sel(longitude=slice(min_lon,max_lon), latitude=slice(min_lat,max_lat)).chunk('auto')\n",
    "    ds = ds.persist()\n",
    "    dsets.append( ds )\n",
    "\n",
    "dsets[0]   # shows one time slice example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7475fd-c396-40ba-a0d6-8524ce98ba75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Concatenate all dates / datasets\n",
    "ds_subs = xr.concat(dsets, dim='time').sortby('time').persist()\n",
    "ds_subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aefff77-2f79-4c80-8eb4-3b3d1a03c95f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "### Generate coastline and land mask for current dataset\n",
    "land_mask, shp_poly = get_coastline( ds_lon_vec=ds_subs.longitude.values.copy(),\n",
    "                                     ds_lat_vec=ds_subs.latitude.values.copy(), buf=0.2 )  #, verbose=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63004696-4b19-4ab6-a7a4-8a0420894a9d",
   "metadata": {},
   "source": [
    "## Demo plots for selected month and year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e2aaff-61ce-42a9-8ef4-f0587681f16e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "latData = ds_subs.latitude[:]\n",
    "lonData = ds_subs.longitude[:]\n",
    "TIME = ds_subs.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dad48fe-ab45-47cf-8779-a3016ebec1f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt_ind = np.linspace(1, ds_subs.sizes['time']-1, 6, dtype='int') - 1   # some selected time slices to display\n",
    "pp = ds_subs.ws[plt_ind,:,:].plot( col='time', col_wrap=3, robust=True, cmap=jett, figsize=(18,10), \n",
    "                                   cbar_kwargs={'label':'wind speed in [' + ds_subs.ws.units + ']'} )\n",
    "\n",
    "for ii,ax in enumerate(pp.axs.flat):\n",
    "    ax.set_aspect('equal','box')\n",
    "    ax.set_title(f\"time = {str(TIME[plt_ind[ii]].values).split('.')[0]}\")\n",
    "    ax.quiver(lonData[:], latData[:], ds_subs.uwnd[plt_ind[ii]], ds_subs.vwnd[plt_ind[ii]] )\n",
    "    land_mask.plot(ax=ax, add_colorbar=False, add_labels=False, cmap=cmp)\n",
    "    shp_poly.boundary.plot(ax=ax, color='black', linewidth=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e99e199-f416-42db-a5b1-fc6f3a885542",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if n_workers is None:  # local Dask cluster\n",
    "    cluster.close()\n",
    "    client.shutdown()\n",
    "else:   # Gateway cluster\n",
    "    cluster.shutdown()\n",
    "    client.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171b0dce-f6c9-4ebd-b4a7-9d5b04651198",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### End notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
